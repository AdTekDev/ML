# Project 

---

Applying and Comparing Machine Learning Algorithms   

**Objective:**
Students are required to select **one real-world problem** and apply **three different machine learning algorithms** representing three learning paradigms:

* **Supervised Learning**: e.g., Logistic Regression or Random Forest
* **Unsupervised Learning**: e.g., KMeans Clustering
* **Semi-Supervised Learning**: e.g., LabelPropagation

The goal is to **train, evaluate, and compare** these approaches on the same dataset to understand their effectiveness and limitations.

---

## **Requirements**

1. **Problem Selection**

   * Choose a real-world dataset (e.g., healthcare prediction, customer churn, text classification).
   * The dataset must contain both features and class labels.

2. **Data Preparation**

   * Handle missing values, normalize or scale numerical features, and encode categorical variables.
   * Split data into training and testing sets (for supervised and semi-supervised learning).

3. **Model Training & Testing**

   * **Supervised Learning**: Train a classifier (Logistic Regression, Random Forest, or equivalent).
   * **Unsupervised Learning**: Apply clustering (KMeans) and map clusters to labels for evaluation.
   * **Semi-Supervised Learning**: Hide a portion of the labels and apply LabelPropagation to infer missing labels.

4. **Evaluation Metrics**

   * **Supervised & Semi-supervised**: Accuracy, Precision, Recall, F1-score.
   * **Unsupervised**: Silhouette Score, Adjusted Rand Index (ARI).

5. **Comparison & Discussion**

   * Compare the performance of the three approaches.
   * Discuss their strengths, weaknesses, and suitability for the chosen problem.
   * Highlight situations where each method would be most appropriate.

6. **Deliverables**

   * pptx (20 - 30 slides) including:

     * Problem description and dataset overview.
     * Data preprocessing steps.
     * Model training procedures.
     * Evaluation results (tables, charts, or graphs).
     * Comparative analysis and conclusion.
   * Source code (well-documented, reproducible).
   * Data - Model 

## **Evaluation Criteria**

* **Understanding of Algorithms (20%)** – Clear explanation of principles and workflow.
* **Implementation & Experimentation (25%)** – Correct application of all three algorithms.
* **Evaluation & Comparison (25%)** – Proper use of metrics, meaningful comparison.
* **Clarity of Report (20%)** – Structured, concise, with visualizations.
* **Code Quality (10%)** – Readable, reproducible, with comments.
